{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import boto3\n",
    "\n",
    "#cred = boto3.Session().get_credentials()\n",
    "\n",
    "# s3://cosmicenergy-ml-public-datasets/flight_data/raw_files/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2015_1.zip\n",
    "\n",
    "#conn = boto3.client('s3')\n",
    "conn = boto3.client('s3',\n",
    "    endpoint_url='http://localhost:9000',\n",
    "    aws_access_key_id='minioadmin',\n",
    "    aws_secret_access_key='minioadmin',\n",
    "    aws_session_token=None,\n",
    "    config=boto3.session.Config(signature_version='s3v4'),\n",
    "    verify=False\n",
    ")\n",
    "s3_list = []\n",
    "for key in conn.list_objects_v2(Bucket=\"cosmicenergy-ml-public-datasets\",Prefix='flight_data')['Contents']:\n",
    "    if (len(key['Key'].split(\"/\")) > 1) and (\"On_Time_Reporting\" in key['Key'].split(\"/\")[1]):\n",
    "        #print(key['Key'].split(\"/\")[2])\n",
    "        s3_list.append(key['Key'].split(\"/\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s3_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeff/tmp/cml_flight_demo/penv38/lib/python3.8/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'transtats.bts.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"http://transtats.bts.gov/PREZIP/\"\n",
    "req = requests.get(url,verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(req.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "len(soup.find_all(href=re.compile(\"On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "for year in range((today.year)-5,(today.year)+1):\n",
    "    print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_list = []\n",
    "import datetime\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "for year in range((today.year)-5,(today.year)+1):\n",
    "    for files in soup.find_all(href=re.compile(f\"On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}\")):\n",
    "        live_list.append(files.contents[0])\n",
    "    #print(files.contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(live_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = list(set(live_list).difference(set(s3_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_5.zip',\n",
       " 'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_3.zip',\n",
       " 'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_7.zip',\n",
       " 'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_1.zip',\n",
       " 'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_6.zip',\n",
       " 'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_4.zip']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeff/tmp/cml_flight_demo/penv38/lib/python3.8/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'transtats.bts.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# THIS ONE!! \n",
    "#  Fetch the file from transtats and save locally\n",
    "import requests\n",
    "import zipfile\n",
    "from smart_open import open\n",
    "from io import BytesIO\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "filename = \"On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_4\"\n",
    "\n",
    "URL = f\"https://transtats.bts.gov/PREZIP/{filename}.zip\"\n",
    "response = requests.get(URL,verify=False)\n",
    "\n",
    "with zipfile.ZipFile(BytesIO(response.content)) as zip:\n",
    "    bob = zip.infolist()\n",
    "    for info in zip.infolist():\n",
    "        if \"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)\" in info.filename:\n",
    "            file_bytes = zip.read(info.filename)\n",
    "\n",
    "with open(f's3://{os.environ[\"AWS_KEY\"]}:{os.environ[\"AWS_SECRET\"]}@jfletcher-datasets/flight_data/transtats/{filename}.csv.gz', 'wb') as fout:\n",
    "    fout.write(file_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Key': 'smaller.csv', 'LastModified': datetime.datetime(2022, 10, 20, 14, 39, 44, 587000, tzinfo=tzutc()), 'ETag': '\"e9ef2216b718c3b6daac661c4396de39\"', 'Size': 5701, 'StorageClass': 'STANDARD', 'Owner': {'DisplayName': 'minio', 'ID': '02d6176db174dc93cb1b899f7c6078f08654445fe8cf1b6ce98d8855f66bdbf4'}}]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "conn = boto3.session(\n",
    "    endpoint_url='http://localhost:9000',\n",
    "    aws_access_key_id='minioadmin',\n",
    "    aws_secret_access_key='minioadmin',\n",
    "    aws_session_token=None,\n",
    "    config=boto3.session.Config(signature_version='s3v4'),\n",
    "    verify=False\n",
    ")\n",
    "s3_list = []\n",
    "print(conn.list_objects_v2(Bucket=\"test\")['Contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid endpoint: https://?host=http%3A%2F%2F192.168.1.101%3A9000:443",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 22\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# from smart_open import open\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# import os, boto3\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m#     #verify=False\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m#     )\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39ms3://minioadmin:minioadmin@?host=http\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m3A\u001b[39;49m\u001b[39m%2F\u001b[39;49;00m\u001b[39m%2F\u001b[39;49;00m\u001b[39m192.168.1.101\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m3A9000@test/smaller.cvs\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[1;32m     23\u001b[0m     \u001b[39mprint\u001b[39m(line)\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/smart_open/smart_open_lib.py:224\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m ve:\n\u001b[1;32m    222\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(ve\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 224\u001b[0m binary \u001b[39m=\u001b[39m _open_binary_stream(uri, binary_mode, transport_params)\n\u001b[1;32m    225\u001b[0m decompressed \u001b[39m=\u001b[39m so_compression\u001b[39m.\u001b[39mcompression_wrapper(binary, binary_mode, compression)\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mor\u001b[39;00m explicit_encoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/smart_open/smart_open_lib.py:400\u001b[0m, in \u001b[0;36m_open_binary_stream\u001b[0;34m(uri, mode, transport_params)\u001b[0m\n\u001b[1;32m    398\u001b[0m scheme \u001b[39m=\u001b[39m _sniff_scheme(uri)\n\u001b[1;32m    399\u001b[0m submodule \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39mget_transport(scheme)\n\u001b[0;32m--> 400\u001b[0m fobj \u001b[39m=\u001b[39m submodule\u001b[39m.\u001b[39;49mopen_uri(uri, mode, transport_params)\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(fobj, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    402\u001b[0m     fobj\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m uri\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/smart_open/s3.py:224\u001b[0m, in \u001b[0;36mopen_uri\u001b[0;34m(uri, mode, transport_params)\u001b[0m\n\u001b[1;32m    222\u001b[0m parsed_uri, transport_params \u001b[39m=\u001b[39m _consolidate_params(parsed_uri, transport_params)\n\u001b[1;32m    223\u001b[0m kwargs \u001b[39m=\u001b[39m smart_open\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheck_kwargs(\u001b[39mopen\u001b[39m, transport_params)\n\u001b[0;32m--> 224\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(parsed_uri[\u001b[39m'\u001b[39;49m\u001b[39mbucket_id\u001b[39;49m\u001b[39m'\u001b[39;49m], parsed_uri[\u001b[39m'\u001b[39;49m\u001b[39mkey_id\u001b[39;49m\u001b[39m'\u001b[39;49m], mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/smart_open/s3.py:291\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(bucket_id, key_id, mode, version_id, buffer_size, min_part_size, multipart_upload, defer_seek, client, client_kwargs, writebuffer)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mversion_id must be None when writing\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    290\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m constants\u001b[39m.\u001b[39mREAD_BINARY:\n\u001b[0;32m--> 291\u001b[0m     fileobj \u001b[39m=\u001b[39m Reader(\n\u001b[1;32m    292\u001b[0m         bucket_id,\n\u001b[1;32m    293\u001b[0m         key_id,\n\u001b[1;32m    294\u001b[0m         version_id\u001b[39m=\u001b[39;49mversion_id,\n\u001b[1;32m    295\u001b[0m         buffer_size\u001b[39m=\u001b[39;49mbuffer_size,\n\u001b[1;32m    296\u001b[0m         defer_seek\u001b[39m=\u001b[39;49mdefer_seek,\n\u001b[1;32m    297\u001b[0m         client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    298\u001b[0m         client_kwargs\u001b[39m=\u001b[39;49mclient_kwargs,\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    300\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m constants\u001b[39m.\u001b[39mWRITE_BINARY:\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m multipart_upload:\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/smart_open/s3.py:555\u001b[0m, in \u001b[0;36mReader.__init__\u001b[0;34m(self, bucket, key, version_id, buffer_size, line_terminator, defer_seek, client, client_kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_version_id \u001b[39m=\u001b[39m version_id\n\u001b[1;32m    553\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer_size \u001b[39m=\u001b[39m buffer_size\n\u001b[0;32m--> 555\u001b[0m _initialize_boto3(\u001b[39mself\u001b[39;49m, client, client_kwargs, bucket, key)\n\u001b[1;32m    557\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_reader \u001b[39m=\u001b[39m _SeekableRawReader(\n\u001b[1;32m    558\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client,\n\u001b[1;32m    559\u001b[0m     bucket,\n\u001b[1;32m    560\u001b[0m     key,\n\u001b[1;32m    561\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_version_id,\n\u001b[1;32m    562\u001b[0m )\n\u001b[1;32m    563\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_pos \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/smart_open/s3.py:528\u001b[0m, in \u001b[0;36m_initialize_boto3\u001b[0;34m(rw, client, client_kwargs, bucket, key)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[39mif\u001b[39;00m client \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     init_kwargs \u001b[39m=\u001b[39m client_kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mS3.Client\u001b[39m\u001b[39m'\u001b[39m, {})\n\u001b[0;32m--> 528\u001b[0m     client \u001b[39m=\u001b[39m boto3\u001b[39m.\u001b[39;49mclient(\u001b[39m'\u001b[39;49m\u001b[39ms3\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minit_kwargs)\n\u001b[1;32m    529\u001b[0m \u001b[39massert\u001b[39;00m client\n\u001b[1;32m    531\u001b[0m rw\u001b[39m.\u001b[39m_client \u001b[39m=\u001b[39m _ClientWrapper(client, client_kwargs)\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/boto3/__init__.py:92\u001b[0m, in \u001b[0;36mclient\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclient\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39m    Create a low-level service client by name using the default session.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[39m    See :py:meth:`boto3.session.Session.client`.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_default_session()\u001b[39m.\u001b[39;49mclient(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/boto3/session.py:299\u001b[0m, in \u001b[0;36mSession.client\u001b[0;34m(self, service_name, region_name, api_version, use_ssl, verify, endpoint_url, aws_access_key_id, aws_secret_access_key, aws_session_token, config)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclient\u001b[39m(\n\u001b[1;32m    218\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    219\u001b[0m     service_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m     config\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    229\u001b[0m ):\n\u001b[1;32m    230\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m    Create a low-level service client by name.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m \n\u001b[1;32m    298\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49mcreate_client(\n\u001b[1;32m    300\u001b[0m         service_name,\n\u001b[1;32m    301\u001b[0m         region_name\u001b[39m=\u001b[39;49mregion_name,\n\u001b[1;32m    302\u001b[0m         api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[1;32m    303\u001b[0m         use_ssl\u001b[39m=\u001b[39;49muse_ssl,\n\u001b[1;32m    304\u001b[0m         verify\u001b[39m=\u001b[39;49mverify,\n\u001b[1;32m    305\u001b[0m         endpoint_url\u001b[39m=\u001b[39;49mendpoint_url,\n\u001b[1;32m    306\u001b[0m         aws_access_key_id\u001b[39m=\u001b[39;49maws_access_key_id,\n\u001b[1;32m    307\u001b[0m         aws_secret_access_key\u001b[39m=\u001b[39;49maws_secret_access_key,\n\u001b[1;32m    308\u001b[0m         aws_session_token\u001b[39m=\u001b[39;49maws_session_token,\n\u001b[1;32m    309\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    310\u001b[0m     )\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/botocore/session.py:976\u001b[0m, in \u001b[0;36mcreate_client\u001b[0;34m(self, service_name, region_name, api_version, use_ssl, verify, endpoint_url, aws_access_key_id, aws_secret_access_key, aws_session_token, config)\u001b[0m\n\u001b[1;32m    973\u001b[0m         region_name = self.get_config_variable('region')\n\u001b[1;32m    975\u001b[0m validate_region_name(region_name)\n\u001b[0;32m--> 976\u001b[0m # For any client that we create in retrieving credentials\n\u001b[1;32m    977\u001b[0m # we want to create it using the same region as specified in\n\u001b[1;32m    978\u001b[0m # creating this client. It is important to note though that the\n\u001b[1;32m    979\u001b[0m # credentials client is only created once per session. So if a new\n\u001b[1;32m    980\u001b[0m # client is created with a different region, its credential resolver\n\u001b[1;32m    981\u001b[0m # will use the region of the first client. However, that is not an\n\u001b[1;32m    982\u001b[0m # issue as of now because the credential resolver uses only STS and\n\u001b[1;32m    983\u001b[0m # the credentials returned at regional endpoints are valid across\n\u001b[1;32m    984\u001b[0m # all regions in the partition.\n\u001b[1;32m    985\u001b[0m self._last_client_region_used = region_name\n\u001b[1;32m    986\u001b[0m return region_name\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/botocore/client.py:126\u001b[0m, in \u001b[0;36mcreate_client\u001b[0;34m(self, service_name, region_name, is_secure, endpoint_url, verify, credentials, scoped_config, api_version, client_config, auth_token)\u001b[0m\n\u001b[1;32m    113\u001b[0m region_name, client_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_normalize_fips_region(\n\u001b[1;32m    114\u001b[0m     region_name, client_config\n\u001b[1;32m    115\u001b[0m )\n\u001b[1;32m    116\u001b[0m endpoint_bridge \u001b[39m=\u001b[39m ClientEndpointBridge(\n\u001b[1;32m    117\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_endpoint_resolver,\n\u001b[1;32m    118\u001b[0m     scoped_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config_store\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config_store,\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    123\u001b[0m client_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_client_args(\n\u001b[1;32m    124\u001b[0m     service_model,\n\u001b[1;32m    125\u001b[0m     region_name,\n\u001b[0;32m--> 126\u001b[0m     is_secure,\n\u001b[1;32m    127\u001b[0m     endpoint_url,\n\u001b[1;32m    128\u001b[0m     verify,\n\u001b[1;32m    129\u001b[0m     credentials,\n\u001b[1;32m    130\u001b[0m     scoped_config,\n\u001b[1;32m    131\u001b[0m     client_config,\n\u001b[1;32m    132\u001b[0m     endpoint_bridge,\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m service_client \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mclient_args)\n\u001b[1;32m    135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_register_retries(service_client)\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/botocore/client.py:471\u001b[0m, in \u001b[0;36m_get_client_args\u001b[0;34m(self, service_model, region_name, is_secure, endpoint_url, verify, credentials, scoped_config, client_config, endpoint_bridge, auth_token)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_client_args\u001b[39m(\n\u001b[1;32m    447\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    448\u001b[0m     service_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m     endpoint_bridge,\n\u001b[1;32m    457\u001b[0m ):\n\u001b[1;32m    458\u001b[0m     args_creator \u001b[39m=\u001b[39m ClientArgsCreator(\n\u001b[1;32m    459\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_emitter,\n\u001b[1;32m    460\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_user_agent,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    464\u001b[0m         config_store\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config_store,\n\u001b[1;32m    465\u001b[0m     )\n\u001b[1;32m    466\u001b[0m     \u001b[39mreturn\u001b[39;00m args_creator\u001b[39m.\u001b[39mget_client_args(\n\u001b[1;32m    467\u001b[0m         service_model,\n\u001b[1;32m    468\u001b[0m         region_name,\n\u001b[1;32m    469\u001b[0m         is_secure,\n\u001b[1;32m    470\u001b[0m         endpoint_url,\n\u001b[0;32m--> 471\u001b[0m         verify,\n\u001b[1;32m    472\u001b[0m         credentials,\n\u001b[1;32m    473\u001b[0m         scoped_config,\n\u001b[1;32m    474\u001b[0m         client_config,\n\u001b[1;32m    475\u001b[0m         endpoint_bridge,\n\u001b[1;32m    476\u001b[0m     )\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/botocore/args.py:126\u001b[0m, in \u001b[0;36mget_client_args\u001b[0;34m(self, service_model, region_name, is_secure, endpoint_url, verify, credentials, scoped_config, client_config, endpoint_bridge, auth_token)\u001b[0m\n\u001b[1;32m    120\u001b[0m new_config \u001b[39m=\u001b[39m Config(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig_kwargs)\n\u001b[1;32m    121\u001b[0m endpoint_creator \u001b[39m=\u001b[39m EndpointCreator(event_emitter)\n\u001b[1;32m    123\u001b[0m endpoint \u001b[39m=\u001b[39m endpoint_creator\u001b[39m.\u001b[39mcreate_endpoint(\n\u001b[1;32m    124\u001b[0m     service_model,\n\u001b[1;32m    125\u001b[0m     region_name\u001b[39m=\u001b[39mendpoint_region_name,\n\u001b[0;32m--> 126\u001b[0m     endpoint_url\u001b[39m=\u001b[39mendpoint_config[\u001b[39m'\u001b[39m\u001b[39mendpoint_url\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    127\u001b[0m     verify\u001b[39m=\u001b[39mverify,\n\u001b[1;32m    128\u001b[0m     response_parser_factory\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_parser_factory,\n\u001b[1;32m    129\u001b[0m     max_pool_connections\u001b[39m=\u001b[39mnew_config\u001b[39m.\u001b[39mmax_pool_connections,\n\u001b[1;32m    130\u001b[0m     proxies\u001b[39m=\u001b[39mnew_config\u001b[39m.\u001b[39mproxies,\n\u001b[1;32m    131\u001b[0m     timeout\u001b[39m=\u001b[39m(new_config\u001b[39m.\u001b[39mconnect_timeout, new_config\u001b[39m.\u001b[39mread_timeout),\n\u001b[1;32m    132\u001b[0m     socket_options\u001b[39m=\u001b[39msocket_options,\n\u001b[1;32m    133\u001b[0m     client_cert\u001b[39m=\u001b[39mnew_config\u001b[39m.\u001b[39mclient_cert,\n\u001b[1;32m    134\u001b[0m     proxies_config\u001b[39m=\u001b[39mnew_config\u001b[39m.\u001b[39mproxies_config,\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    137\u001b[0m serializer \u001b[39m=\u001b[39m botocore\u001b[39m.\u001b[39mserialize\u001b[39m.\u001b[39mcreate_serializer(\n\u001b[1;32m    138\u001b[0m     protocol, parameter_validation\n\u001b[1;32m    139\u001b[0m )\n\u001b[1;32m    140\u001b[0m response_parser \u001b[39m=\u001b[39m botocore\u001b[39m.\u001b[39mparsers\u001b[39m.\u001b[39mcreate_parser(protocol)\n",
      "File \u001b[0;32m~/tmp/airflow_flight_demo/penv/lib/python3.9/site-packages/botocore/endpoint.py:402\u001b[0m, in \u001b[0;36mEndpointCreator.create_endpoint\u001b[0;34m(self, service_model, region_name, endpoint_url, verify, response_parser_factory, timeout, max_pool_connections, http_session_cls, proxies, socket_options, client_cert, proxies_config)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_endpoint\u001b[39m(\n\u001b[1;32m    385\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    386\u001b[0m     service_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     proxies_config\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ):\n\u001b[1;32m    399\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_valid_endpoint_url(\n\u001b[1;32m    400\u001b[0m         endpoint_url\n\u001b[1;32m    401\u001b[0m     ) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_valid_ipv6_endpoint_url(endpoint_url):\n\u001b[0;32m--> 402\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid endpoint: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m endpoint_url)\n\u001b[1;32m    404\u001b[0m     \u001b[39mif\u001b[39;00m proxies \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         proxies \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_proxies(endpoint_url)\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid endpoint: https://?host=http%3A%2F%2F192.168.1.101%3A9000:443"
     ]
    }
   ],
   "source": [
    "# from smart_open import open\n",
    "\n",
    "# import os, boto3\n",
    "# # session = boto3.Session(\n",
    "# #     endpoint_url='http://localhost:9000',\n",
    "# #     aws_access_key_id='minioadmin',\n",
    "# #     aws_secret_access_key='minioadmin',\n",
    "# #     aws_session_token=None,\n",
    "# #     config=boto3.session.Config(signature_version='s3v4'),\n",
    "# #     verify=False\n",
    "# # )\n",
    "\n",
    "# client = boto3.client('s3', \n",
    "#     endpoint_url='http://localhost:9000',\n",
    "#     aws_access_key_id='minioadmin',\n",
    "#     aws_secret_access_key='minioadmin',\n",
    "#     #aws_session_token=None,\n",
    "#     #config=boto3.session.Config(signature_version='s3v4'),\n",
    "#     #verify=False\n",
    "#     )\n",
    "\n",
    "for line in open(\"s3://minioadmin:minioadmin@?host=http%3A%2F%2F192.168.1.101%3A9000@test/smaller.cvs\"):\n",
    "    print(line)\n",
    "\n",
    "# for line in open(\"s3://test/smaller.csv\",transport_params={'client': client}):\n",
    "#     print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Year\",\"Quarter\",\"Month\",\"DayofMonth\",\"DayOfWeek\",\"FlightDate\",\"Reporting_Airline\",\"DOT_ID_Reporting'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_bytes.decode()[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('ziper2.gz', 'wt') as f:\n",
    "    f.write(file_bytes.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_open import open\n",
    "with open('zipper.gz','wb') as fout:\n",
    "        fout.write(file_bytes)\n",
    "    # with gzip.GzipFile(fileobj=fout,mode='w') as f_zip:\n",
    "    #     f_zip.write(BytesIO(file_bytes))\n",
    "\n",
    "    # with gzip.open(fout,'wb') as f:\n",
    "    #     f.write(file_bytes)\n",
    "    # g = gzip.GzipFile(fileobj=fout, mode='w')\n",
    "    # g.write(file_bytes.decode())\n",
    "    # g.close()\n",
    "#    with gzip.GzipFile(fileobj=fout, mode='w') as f_zip:\n",
    "#        f_zip.writelines(BytesIO(file_bytes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/b81vd85d6bs0qx8zh86b5m780000gn/T/ipykernel_64402/1751591345.py:3: DtypeWarning: Columns (76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Users/jeff/tmp/cml_flight_demo/data/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2022_1.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/jeff/tmp/cml_flight_demo/data/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2022_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'SH87MVX8Q6DSM1ZY',\n",
       "  'HostId': 'SGt1leezJ1OoTCKJamvs0kPhSNeWCjQonxpY7qzDj5XL3ywScOxUbqqyOK2W2INwBWeIcUvndmc=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'SGt1leezJ1OoTCKJamvs0kPhSNeWCjQonxpY7qzDj5XL3ywScOxUbqqyOK2W2INwBWeIcUvndmc=',\n",
       "   'x-amz-request-id': 'SH87MVX8Q6DSM1ZY',\n",
       "   'date': 'Tue, 18 Oct 2022 21:58:46 GMT',\n",
       "   'etag': '\"f06f6f027abefbb3409f5ecb78a83793\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"f06f6f027abefbb3409f5ecb78a83793\"'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import boto3\n",
    "\n",
    "cred = boto3.Session().get_credentials()\n",
    "\n",
    "s3 = boto3.client('s3',\n",
    "   aws_access_key_id = os.environ[\"AWS_KEY\"],\n",
    "   aws_secret_access_key = os.environ[\"AWS_SECRET\"],\n",
    ")\n",
    "bucketname = 'jfletcher-datasets'\n",
    "key = 'flight_data/transtats/test.csv.gz'\n",
    "\n",
    "#s3.upload_fileobj(file_bytes, bucketname, key)\n",
    "s3.put_object(Body=gzip.compress(file_bytes),Bucket= bucketname,Key =key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                                 int64\n",
      "Quarter                              int64\n",
      "Month                                int64\n",
      "DayofMonth                           int64\n",
      "DayOfWeek                            int64\n",
      "FlightDate                          object\n",
      "Reporting_Airline                   object\n",
      "DOT_ID_Reporting_Airline             int64\n",
      "IATA_CODE_Reporting_Airline         object\n",
      "Tail_Number                         object\n",
      "Flight_Number_Reporting_Airline      int64\n",
      "OriginAirportID                      int64\n",
      "OriginAirportSeqID                   int64\n",
      "OriginCityMarketID                   int64\n",
      "Origin                              object\n",
      "OriginCityName                      object\n",
      "OriginState                         object\n",
      "OriginStateFips                      int64\n",
      "OriginStateName                     object\n",
      "OriginWac                            int64\n",
      "DestAirportID                        int64\n",
      "DestAirportSeqID                     int64\n",
      "DestCityMarketID                     int64\n",
      "Dest                                object\n",
      "DestCityName                        object\n",
      "DestState                           object\n",
      "DestStateFips                        int64\n",
      "DestStateName                       object\n",
      "DestWac                              int64\n",
      "CRSDepTime                           int64\n",
      "DepTime                            float64\n",
      "DepDelay                           float64\n",
      "DepDelayMinutes                    float64\n",
      "DepDel15                           float64\n",
      "DepartureDelayGroups               float64\n",
      "DepTimeBlk                          object\n",
      "TaxiOut                            float64\n",
      "WheelsOff                          float64\n",
      "WheelsOn                           float64\n",
      "TaxiIn                             float64\n",
      "CRSArrTime                           int64\n",
      "ArrTime                            float64\n",
      "ArrDelay                           float64\n",
      "ArrDelayMinutes                    float64\n",
      "ArrDel15                           float64\n",
      "ArrivalDelayGroups                 float64\n",
      "ArrTimeBlk                          object\n",
      "Cancelled                          float64\n",
      "CancellationCode                    object\n",
      "Diverted                           float64\n",
      "CRSElapsedTime                     float64\n",
      "ActualElapsedTime                  float64\n",
      "AirTime                            float64\n",
      "Flights                            float64\n",
      "Distance                           float64\n",
      "DistanceGroup                        int64\n",
      "CarrierDelay                       float64\n",
      "WeatherDelay                       float64\n",
      "NASDelay                           float64\n",
      "SecurityDelay                      float64\n",
      "LateAircraftDelay                  float64\n",
      "FirstDepTime                       float64\n",
      "TotalAddGTime                      float64\n",
      "LongestAddGTime                    float64\n",
      "DivAirportLandings                   int64\n",
      "DivReachedDest                     float64\n",
      "DivActualElapsedTime               float64\n",
      "DivArrDelay                        float64\n",
      "DivDistance                        float64\n",
      "Div1Airport                         object\n",
      "Div1AirportID                      float64\n",
      "Div1AirportSeqID                   float64\n",
      "Div1WheelsOn                       float64\n",
      "Div1TotalGTime                     float64\n",
      "Div1LongestGTime                   float64\n",
      "Div1WheelsOff                      float64\n",
      "Div1TailNum                         object\n",
      "Div2Airport                         object\n",
      "Div2AirportID                      float64\n",
      "Div2AirportSeqID                   float64\n",
      "Div2WheelsOn                       float64\n",
      "Div2TotalGTime                     float64\n",
      "Div2LongestGTime                   float64\n",
      "Div2WheelsOff                      float64\n",
      "Div2TailNum                         object\n",
      "Div3Airport                        float64\n",
      "Div3AirportID                      float64\n",
      "Div3AirportSeqID                   float64\n",
      "Div3WheelsOn                       float64\n",
      "Div3TotalGTime                     float64\n",
      "Div3LongestGTime                   float64\n",
      "Div3WheelsOff                      float64\n",
      "Div3TailNum                        float64\n",
      "Div4Airport                        float64\n",
      "Div4AirportID                      float64\n",
      "Div4AirportSeqID                   float64\n",
      "Div4WheelsOn                       float64\n",
      "Div4TotalGTime                     float64\n",
      "Div4LongestGTime                   float64\n",
      "Div4WheelsOff                      float64\n",
      "Div4TailNum                        float64\n",
      "Div5Airport                        float64\n",
      "Div5AirportID                      float64\n",
      "Div5AirportSeqID                   float64\n",
      "Div5WheelsOn                       float64\n",
      "Div5TotalGTime                     float64\n",
      "Div5LongestGTime                   float64\n",
      "Div5WheelsOff                      float64\n",
      "Div5TailNum                        float64\n",
      "Unnamed: 109                       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):       print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jeff/tmp/cml_flight_demo/data\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/jeff/tmp/cml_flight_demo/data\")\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_3.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\".\")\n",
    "with zipfile.ZipFile(\"On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_3.zip\", mode=\"w\") as archive:\n",
    "    archive.write(\"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2022_1.csv\",compress_type=zipfile.ZIP_DEFLATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function open in smart_open:\n",
      "\n",
      "smart_open.open = open(uri, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None, compression='infer_from_extension', transport_params=None)\n",
      "    Open the URI object, returning a file-like object.\n",
      "    \n",
      "    The URI is usually a string in a variety of formats.\n",
      "    For a full list of examples, see the :func:`parse_uri` function.\n",
      "    \n",
      "    The URI may also be one of:\n",
      "    \n",
      "    - an instance of the pathlib.Path class\n",
      "    - a stream (anything that implements io.IOBase-like functionality)\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    uri: str or object\n",
      "        The object to open.\n",
      "    mode: str, optional\n",
      "        Mimicks built-in open parameter of the same name.\n",
      "    buffering: int, optional\n",
      "        Mimicks built-in open parameter of the same name.\n",
      "    encoding: str, optional\n",
      "        Mimicks built-in open parameter of the same name.\n",
      "    errors: str, optional\n",
      "        Mimicks built-in open parameter of the same name.\n",
      "    newline: str, optional\n",
      "        Mimicks built-in open parameter of the same name.\n",
      "    closefd: boolean, optional\n",
      "        Mimicks built-in open parameter of the same name.  Ignored.\n",
      "    opener: object, optional\n",
      "        Mimicks built-in open parameter of the same name.  Ignored.\n",
      "    compression: str, optional (see smart_open.compression.get_supported_compression_types)\n",
      "        Explicitly specify the compression/decompression behavior.\n",
      "    transport_params: dict, optional\n",
      "        Additional parameters for the transport layer (see notes below).\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    A file-like object.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    smart_open has several implementations for its transport layer (e.g. S3, HTTP).\n",
      "    Each transport layer has a different set of keyword arguments for overriding\n",
      "    default behavior.  If you specify a keyword argument that is *not* supported\n",
      "    by the transport layer being used, smart_open will ignore that argument and\n",
      "    log a warning message.\n",
      "    \n",
      "    smart_open supports the following transport mechanisms:\n",
      "    \n",
      "    file (smart_open/local_file.py)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Implements the transport for the file:// schema.\n",
      "    \n",
      "    hdfs (smart_open/hdfs.py)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Implements reading and writing to/from HDFS.\n",
      "    \n",
      "    http (smart_open/http.py)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Implements file-like objects for reading from http.\n",
      "    \n",
      "    kerberos: boolean, optional\n",
      "        If True, will attempt to use the local Kerberos credentials\n",
      "    user: str, optional\n",
      "        The username for authenticating over HTTP\n",
      "    password: str, optional\n",
      "        The password for authenticating over HTTP\n",
      "    headers: dict, optional\n",
      "        Any headers to send in the request. If ``None``, the default headers are sent:\n",
      "        ``{'Accept-Encoding': 'identity'}``. To use no headers at all,\n",
      "        set this variable to an empty dict, ``{}``.\n",
      "    \n",
      "    s3 (smart_open/s3.py)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~\n",
      "    Implements file-like objects for reading and writing from/to AWS S3.\n",
      "    \n",
      "    buffer_size: int, optional\n",
      "        The buffer size to use when performing I/O.\n",
      "    min_part_size: int, optional\n",
      "        The minimum part size for multipart uploads.  For writing only.\n",
      "    multipart_upload: bool, optional\n",
      "        Default: `True`\n",
      "        If set to `True`, will use multipart upload for writing to S3. If set\n",
      "        to `False`, S3 upload will use the S3 Single-Part Upload API, which\n",
      "        is more ideal for small file sizes.\n",
      "        For writing only.\n",
      "    version_id: str, optional\n",
      "        Version of the object, used when reading object.\n",
      "        If None, will fetch the most recent version.\n",
      "    defer_seek: boolean, optional\n",
      "        Default: `False`\n",
      "        If set to `True` on a file opened for reading, GetObject will not be\n",
      "        called until the first seek() or read().\n",
      "        Avoids redundant API queries when seeking before reading.\n",
      "    client: object, optional\n",
      "        The S3 client to use when working with boto3.\n",
      "        If you don't specify this, then smart_open will create a new client for you.\n",
      "    client_kwargs: dict, optional\n",
      "        Additional parameters to pass to the relevant functions of the client.\n",
      "        The keys are fully qualified method names, e.g. `S3.Client.create_multipart_upload`.\n",
      "        The values are kwargs to pass to that method each time it is called.\n",
      "    writebuffer: IO[bytes], optional\n",
      "        By default, this module will buffer data in memory using io.BytesIO\n",
      "        when writing. Pass another binary IO instance here to use it instead.\n",
      "        For example, you may pass a file object to buffer to local disk instead\n",
      "        of in RAM. Use this to keep RAM usage low at the expense of additional\n",
      "        disk IO. If you pass in an open file, then you are responsible for\n",
      "        cleaning it up after writing completes.\n",
      "    \n",
      "    scp (smart_open/ssh.py)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Implements I/O streams over SSH.\n",
      "    \n",
      "    mode: str, optional\n",
      "        The mode to use for opening the file.\n",
      "    host: str, optional\n",
      "        The hostname of the remote machine.  May not be None.\n",
      "    user: str, optional\n",
      "        The username to use to login to the remote machine.\n",
      "        If None, defaults to the name of the current user.\n",
      "    password: str, optional\n",
      "        The password to use to login to the remote machine.\n",
      "    port: int, optional\n",
      "        The port to connect to.\n",
      "    transport_params: dict, optional\n",
      "        Any additional settings to be passed to paramiko.SSHClient.connect\n",
      "    \n",
      "    webhdfs (smart_open/webhdfs.py)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    Implements reading and writing to/from WebHDFS.\n",
      "    \n",
      "    min_part_size: int, optional\n",
      "        For writing only.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    See README.rst\n",
      "    This function also supports transparent compression and decompression \n",
      "    using the following codecs:\n",
      "    \n",
      "    * .bz2\n",
      "    * .gz\n",
      "    \n",
      "    The function depends on the file extension to determine the appropriate codec.\n",
      "    \n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    - `Standard library reference <https://docs.python.org/3.7/library/functions.html#open>`__\n",
      "    - `smart_open README.rst\n",
      "      <https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst>`__\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help('smart_open.open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2022_1.csv\n"
     ]
    }
   ],
   "source": [
    "from smart_open import open\n",
    "import zipfile\n",
    "\n",
    "with open('https://jfletcher-datasets.s3.eu-central-1.amazonaws.com/flight_data/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_1.zip', 'rb') as fin:\n",
    "    with zipfile.ZipFile(fin) as zip:\n",
    "        for info in zip.infolist():\n",
    "            print(info.filename)\n",
    "            #file_bytes = zip.read(info.filename)\n",
    "            #print('%r: %r' % (info.filename, file_bytes.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# conn = boto3.client('s3')\n",
    "import boto3\n",
    "from smart_open import open\n",
    "#tp = {'min_part_size': 5 * 1024**2}\n",
    "with open(\"/Users/jeff/tmp/cml_flight_demo/data/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2022_3.csv\",'r') as fin:\n",
    "    read_data = fin.read()\n",
    "\n",
    "#with open('s3://bucket/key', 'w') as fout:\n",
    "#    fout.write(lots_of_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.snowpark as snp\n",
    "from snowflake.snowpark import functions as F\n",
    "import json\n",
    "#import pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/host/creds_2.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    'account': data['account'],\n",
    "    'user': data['username'],\n",
    "    'password': data['password'],\n",
    "    'role': data['role'],\n",
    "    'warehouse': data['warehouse'],\n",
    "    'database': data['database'],\n",
    "    'schema': data['schema']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = snp.Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.dataframe.DataFrame at 0xffff95db36a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"use sandbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"source\"                                            |\"target\"                                            |\"source_size\"  |\"target_size\"  |\"source_compression\"  |\"target_compression\"  |\"status\"  |\"message\"  |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|On_Time_Reporting_Carrier_On_Time_Performance_1...  |On_Time_Reporting_Carrier_On_Time_Performance_1...  |24222778       |24228208       |NONE                  |GZIP                  |UPLOADED  |           |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.sql(\"PUT 'file://On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_2.zip' @FLIGHT_DATA_STAGE\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"name\"                                              |\"size\"     |\"md5\"                             |\"last_modified\"                |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "|flight_data_stage/2009.csv.gz                       |206299776  |a8fef10a5c6eb655e44b4223dea68010  |Wed, 20 Jul 2022 14:21:03 GMT  |\n",
      "|flight_data_stage/2010.csv.gz                       |208423056  |eaf94007558aa0840b77b9a2d22c1433  |Wed, 20 Jul 2022 14:21:48 GMT  |\n",
      "|flight_data_stage/On_Time_Reporting_Carrier_On_...  |24228208   |02e6c2b60b129cbd012060ee48b94576  |Fri, 19 Aug 2022 14:51:52 GMT  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.sql(\"LIST @FLIGHT_DATA_STAGE\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Dask dataframe requirements are not installed.\n\nPlease either conda or pip install as follows:\n\n  conda install dask                     # either conda install\n  python -m pip install \"dask[dataframe]\" --upgrade  # or python -m pip install",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/dask/array/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m compute\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backends, fft, lib, linalg, ma, overlap, random\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mblockwise\u001b[39;00m \u001b[39mimport\u001b[39;00m atop, blockwise\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/dask/array/backends.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnumpy_compat\u001b[39;00m \u001b[39mimport\u001b[39;00m ma_divide\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpercentile\u001b[39;00m \u001b[39mimport\u001b[39;00m _percentile\n\u001b[1;32m     15\u001b[0m concatenate_lookup\u001b[39m.\u001b[39mregister((\u001b[39mobject\u001b[39m, np\u001b[39m.\u001b[39mndarray), np\u001b[39m.\u001b[39mconcatenate)\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/dask/array/percentile.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhighlevelgraph\u001b[39;00m \u001b[39mimport\u001b[39;00m HighLevelGraph\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Array\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnumpy_compat\u001b[39;00m \u001b[39mimport\u001b[39;00m _numpy_122\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/dask/array/core.py:43\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     36\u001b[0m     DaskMethodsMixin,\n\u001b[1;32m     37\u001b[0m     compute_as_if_collection,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     tokenize,\n\u001b[1;32m     42\u001b[0m )\n\u001b[0;32m---> 43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mblockwise\u001b[39;00m \u001b[39mimport\u001b[39;00m blockwise \u001b[39mas\u001b[39;00m core_blockwise\n\u001b[1;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mblockwise\u001b[39;00m \u001b[39mimport\u001b[39;00m broadcast_dimensions\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/dask/blockwise.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone_key, get_name_from_key, tokenize\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcompatibility\u001b[39;00m \u001b[39mimport\u001b[39;00m prod\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m flatten, keys_in_tasks, reverse_dict\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'prod' from 'dask.compatibility' (/host/penv38-docker/lib/python3.8/site-packages/dask/compatibility.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/dask/dataframe/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m compute\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backends, dispatch, rolling\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     DataFrame,\n\u001b[1;32m      6\u001b[0m     Index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     to_timedelta,\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/dask/dataframe/backends.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdispatch\u001b[39;00m \u001b[39mimport\u001b[39;00m percentile_lookup\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpercentile\u001b[39;00m \u001b[39mimport\u001b[39;00m _percentile\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msizeof\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleSizeof, sizeof\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/dask/array/__init__.py:266\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    260\u001b[0m msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    261\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mDask array requirements are not installed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease either conda or pip install as follows:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m  conda install dask                 # either conda install\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    264\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m  python -m pip install \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdask[array]\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m --upgrade  # or python -m pip install\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    265\u001b[0m )\n\u001b[0;32m--> 266\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39mstr\u001b[39m(e) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'prod' from 'dask.compatibility' (/host/penv38-docker/lib/python3.8/site-packages/dask/compatibility.py)\n\nDask array requirements are not installed.\n\nPlease either conda or pip install as follows:\n\n  conda install dask                 # either conda install\n  python -m pip install \"dask[array]\" --upgrade  # or python -m pip install",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/host/local_testing.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6c6f76696e675f79616c6f77227d/host/local_testing.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ontime \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m/host/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_2.zip\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/modin/logging/logger_function.py:65\u001b[0m, in \u001b[0;36mlogger_decorator.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     67\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m     68\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/modin/pandas/io.py:140\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    138\u001b[0m _, _, _, f_locals \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetargvalues(inspect\u001b[39m.\u001b[39mcurrentframe())\n\u001b[1;32m    139\u001b[0m kwargs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m f_locals\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m _pd_read_csv_signature}\n\u001b[0;32m--> 140\u001b[0m \u001b[39mreturn\u001b[39;00m _read(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/modin/pandas/io.py:57\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     45\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m    Read csv file from local disk.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m    modin.pandas.DataFrame\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     Engine\u001b[39m.\u001b[39;49msubscribe(_update_engine)\n\u001b[1;32m     58\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmodin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexecution\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdispatching\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfactories\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdispatcher\u001b[39;00m \u001b[39mimport\u001b[39;00m FactoryDispatcher\n\u001b[1;32m     60\u001b[0m     squeeze \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39msqueeze\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/modin/config/pubsub.py:213\u001b[0m, in \u001b[0;36mParameter.subscribe\u001b[0;34m(cls, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39mAdd `callback` to the `_subs` list and then execute it.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39m    Callable to execute.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_subs\u001b[39m.\u001b[39mappend(callback)\n\u001b[0;32m--> 213\u001b[0m callback(\u001b[39mcls\u001b[39;49m)\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/modin/pandas/__init__.py:138\u001b[0m, in \u001b[0;36m_update_engine\u001b[0;34m(publisher)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[39mif\u001b[39;00m _is_first_update\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mDask\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    136\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mmodin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexecution\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m initialize_dask\n\u001b[0;32m--> 138\u001b[0m         initialize_dask()\n\u001b[1;32m    139\u001b[0m \u001b[39melif\u001b[39;00m publisher\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCloudray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    140\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmodin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m get_connection\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/modin/core/execution/dask/common/utils.py:22\u001b[0m, in \u001b[0;36minitialize_dask\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitialize_dask\u001b[39m():\n\u001b[1;32m     21\u001b[0m     \u001b[39m\"\"\"Initialize Dask environment.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m default_client\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m         client \u001b[39m=\u001b[39m default_client()\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/distributed/__init__.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m config  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_version\u001b[39;00m \u001b[39mimport\u001b[39;00m get_versions\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mactor\u001b[39;00m \u001b[39mimport\u001b[39;00m Actor, ActorFuture\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     Client,\n\u001b[1;32m     10\u001b[0m     CompatibleExecutor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     wait,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Status, connect, rpc\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/distributed/actor.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mthreading\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m Future\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mprotocol\u001b[39;00m \u001b[39mimport\u001b[39;00m to_serialize\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m iscoroutinefunction, sync, thread_state\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/distributed/client.py:103\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     80\u001b[0m     All,\n\u001b[1;32m     81\u001b[0m     Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m     thread_state,\n\u001b[1;32m     94\u001b[0m )\n\u001b[1;32m     95\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils_comm\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     96\u001b[0m     WrappedKey,\n\u001b[1;32m     97\u001b[0m     gather_from_workers,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     unpack_remotedata,\n\u001b[1;32m    102\u001b[0m )\n\u001b[0;32m--> 103\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mworker\u001b[39;00m \u001b[39mimport\u001b[39;00m get_client, get_worker, secede\n\u001b[1;32m    105\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    107\u001b[0m _global_clients: weakref\u001b[39m.\u001b[39mWeakValueDictionary[\n\u001b[1;32m    108\u001b[0m     \u001b[39mint\u001b[39m, Client\n\u001b[1;32m    109\u001b[0m ] \u001b[39m=\u001b[39m weakref\u001b[39m.\u001b[39mWeakValueDictionary()\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/distributed/worker.py:47\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msystem\u001b[39;00m \u001b[39mimport\u001b[39;00m CPU_COUNT\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     apply,\n\u001b[1;32m     39\u001b[0m     format_bytes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     typename,\n\u001b[1;32m     45\u001b[0m )\n\u001b[0;32m---> 47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m comm, preloading, profile, shuffle, system, utils\n\u001b[1;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbatched\u001b[39;00m \u001b[39mimport\u001b[39;00m BatchedSend\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcomm\u001b[39;00m \u001b[39mimport\u001b[39;00m Comm, connect, get_address_host\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/distributed/shuffle/__init__.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[39mdel\u001b[39;00m pandas\n\u001b[1;32m      7\u001b[0m     SHUFFLE_AVAILABLE \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mshuffle\u001b[39;00m \u001b[39mimport\u001b[39;00m rearrange_by_column_p2p\n\u001b[1;32m     10\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mshuffle_extension\u001b[39;00m \u001b[39mimport\u001b[39;00m ShuffleId, ShuffleMetadata, ShuffleWorkerExtension\n\u001b[1;32m     12\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSHUFFLE_AVAILABLE\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrearrange_by_column_p2p\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mShuffleWorkerExtension\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m ]\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/distributed/shuffle/shuffle.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m tokenize\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataframe\u001b[39;00m \u001b[39mimport\u001b[39;00m DataFrame\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdelayed\u001b[39;00m \u001b[39mimport\u001b[39;00m Delayed, delayed\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhighlevelgraph\u001b[39;00m \u001b[39mimport\u001b[39;00m HighLevelGraph\n",
      "File \u001b[0;32m/host/penv38-docker/lib/python3.8/site-packages/dask/dataframe/__init__.py:62\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m     57\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDask dataframe requirements are not installed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease either conda or pip install as follows:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m  conda install dask                     # either conda install\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m  python -m pip install \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdask[dataframe]\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m --upgrade  # or python -m pip install\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     61\u001b[0m     )\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Dask dataframe requirements are not installed.\n\nPlease either conda or pip install as follows:\n\n  conda install dask                     # either conda install\n  python -m pip install \"dask[dataframe]\" --upgrade  # or python -m pip install"
     ]
    }
   ],
   "source": [
    "ontime = pd.read_csv('/host/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2022_2.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODIN_ENGINE\"]='dask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec0f67cad86913fb0e4be7992dccbf5e1d14b8be84f1f4e5563325d87388bfb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
